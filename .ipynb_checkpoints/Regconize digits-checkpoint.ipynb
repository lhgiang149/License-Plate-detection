{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import cv2\n",
    "import os \n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OCR_scan(img_path = '', pre = 'thresh', save_path = '', number_pics = ''):\n",
    "    image = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    if pre == 'thresh':\n",
    "        ret, gray = cv2.threshold(gray, 0, 255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    elif pre =='blur':\n",
    "        gray = cv2.medianBlur(gray, 3)\n",
    "    save_into = save_path+number_pics+'.jpg'\n",
    "    cv2.imwrite(save_into, gray) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = 'crop_image\\\\'\n",
    "pre1 = 'thresh'\n",
    "pre2 = 'blur'\n",
    "save_path1 = 'preprocess_thresh\\\\'\n",
    "save_path2 = 'preprocess_blur\\\\'\n",
    "count = '1'\n",
    "count_str = 1\n",
    "for i in os.listdir(img_list):\n",
    "    img_path = img_list+i\n",
    "    OCR_scan(img_path = img_path, pre = pre1, save_path = save_path1, number_pics = count)\n",
    "    OCR_scan(img_path = img_path, pre = pre2, save_path = save_path2, number_pics = count)\n",
    "    count_str += 1\n",
    "    count = str(count_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'preprocess_thresh\\\\'\n",
    "list_thresh = []\n",
    "list_blur = []\n",
    "list_o = []\n",
    "list_test = []\n",
    "for i in range(28):\n",
    "    name = i+1\n",
    "    thresh = filename + str(name) + '.jpg'\n",
    "    blur = 'preprocess_blur\\\\'+ str(name) + '.jpg'\n",
    "    original = 'crop_image\\\\'+ str(name) + '.jpg'\n",
    "    test = 'preprocess_test\\\\'+ str(name) + '.jpg'\n",
    "    list_thresh.append(pytesseract.image_to_string(Image.open(thresh)))\n",
    "    list_blur.append(pytesseract.image_to_string(Image.open(blur)))\n",
    "    list_o.append(pytesseract.image_to_string(Image.open(original)))\n",
    "    list_test.append(pytesseract.image_to_string(Image.open(test)))\n",
    "\n",
    "# print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#J 59 PA j\n",
      "664.80\n",
      "#62 HS\n",
      "7108\n",
      "#\n",
      "#\n",
      "#1\n",
      "99.97\n",
      "#\n",
      "#ead\n",
      "043.09\n",
      "#\n",
      "#BY 59-41\n",
      "so7 00\n",
      "#59-81\n",
      "385.59\n",
      "#54-H}\n",
      "6982\n",
      "#\n",
      "#59°51\n",
      "09841\n",
      "#81-61\n",
      "135.56\n",
      "#60-F1\n",
      "506.70\n",
      "#Be \"1\n",
      "0200\n",
      "#16M\n",
      "06.\n",
      "#\n",
      "#S5-Po i\n",
      "2840\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#136.29\n",
      "#\n",
      "#59-(2\n",
      "316.61\n"
     ]
    }
   ],
   "source": [
    "for i in list_thresh:\n",
    "    print('#{}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#59897\n",
      "#B 99°C2\n",
      "012.08\n",
      "#ie\n",
      "043.09\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#39-51\n",
      "098.41\n",
      "#81-61\n",
      "135.56\n",
      "#60:F1\n",
      "506.70\n",
      "#\n",
      "#1\n",
      "0\n",
      "\n",
      "6-H\n",
      "61\n",
      "\n",
      "i\n",
      "#\n",
      "#Gar) ¢\n",
      "7840)\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#136.29\n",
      "#70-01\n",
      "/39 16\n",
      "#39-(2\n",
      "316.01\n"
     ]
    }
   ],
   "source": [
    "for i in list_blur:\n",
    "    print('#{}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#, 59-P1 '\n",
      "664.80\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#136.29\n",
      "#\n",
      "#59-(7\n",
      "316.01\n",
      "#\n",
      "#\n",
      "#\n",
      "#U1]\n",
      "98.97\n",
      "#\n",
      "#78-G)\n",
      "043.08)\n",
      "#59-E]\n",
      "708.50\n",
      "#\n",
      "#\n",
      "#36-HT\n",
      "4882\n",
      "#am 59-51\n",
      "098.41)\n",
      "#81-61\n",
      "1135.56\n",
      "#60-F1\n",
      "506.70\n",
      "#63-/\n",
      "0200\n",
      "#\n",
      "#\n",
      "#55-79\n",
      "7840)\n",
      "#\n",
      "#\n"
     ]
    }
   ],
   "source": [
    "for i in list_o:\n",
    "    print('#{}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unrecognized image mode",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-a657ba8f0905>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# ret, gray = cv2.threshold(closing, 180, 255,cv2.THRESH_BINARY)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'uint8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpytesseract\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[1;34m(obj, mode)\u001b[0m\n\u001b[0;32m   2534\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2536\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfrombuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"raw\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mfrombuffer\u001b[1;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[0;32m   2477\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2478\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2479\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfrombytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mfrombytes\u001b[1;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[0;32m   2409\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2410\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2411\u001b[1;33m     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2412\u001b[0m     \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrombytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2413\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mnew\u001b[1;34m(mode, size, color)\u001b[0m\n\u001b[0;32m   2373\u001b[0m         \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageColor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcolor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2375\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: unrecognized image mode"
     ]
    }
   ],
   "source": [
    "img_path = 'crop_image\\\\1.jpg'\n",
    "image = cv2.imread(img_path,0)\n",
    "# plt.imshow(image, cmap = 'gray')\n",
    "# hist,bins = np.histogram(image.flatten(),256,[0,255]) \n",
    "# plt.imshow(hist,cmap = 'gray')\n",
    "img = cv2.equalizeHist(image)\n",
    "ret, img = cv2.threshold(img, 180, 255,cv2.THRESH_BINARY)\n",
    "\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "# ret, gray = cv2.threshold(closing, 180, 255,cv2.THRESH_BINARY)\n",
    "test = Image.fromarray(closing.astype('uint8'), 'gray')\n",
    "text = pytesseract.image_to_string(Image.open(closing))\n",
    "print(text)\n",
    "plt.imshow(closing, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = 'crop_image\\\\'\n",
    "# img = cv2.imread(img_path,0)\n",
    "# ret, gray = cv2.threshold(img, 150, 255,cv2.THRESH_BINARY)\n",
    "# plt.imshow(gray, cmap = 'gray')\n",
    "def OCR_test(img_path = '', pre = 'thresh', save_path = '', number_pics = ''):\n",
    "    image = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    if pre == 'thresh':\n",
    "        ret, gray = cv2.threshold(gray, 180, 255,cv2.THRESH_BINARY)\n",
    "#     elif pre =='blur':\n",
    "#         gray = cv2.medianBlur(gray, 3)\n",
    "    save_into = save_path+number_pics+'.jpg'\n",
    "    cv2.imwrite(save_into, gray) \n",
    "count = '1'\n",
    "count_str = 1\n",
    "for i in os.listdir(img_list):\n",
    "    img_path = img_list+i\n",
    "    OCR_test(img_path = img_path, pre = 'thresh', save_path = 'preprocess_test\\\\', number_pics = count)\n",
    "    count_str += 1\n",
    "    count = str(count_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#59-P1\n",
      "661.80\n",
      "#\n",
      "#FT,\n",
      "170.78\n",
      "#\n",
      "#59-1\n",
      "98.97]\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#59-B1 |\n",
      "38559\n",
      "#50H\n",
      "6882 fi\n",
      "#\n",
      "#9-51 |\n",
      "098.41]\n",
      "#\n",
      "#§0-F\n",
      "506.70)\n",
      "#63-41]\n",
      "02004\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#ae “TT\n",
      "#\n",
      "#\n",
      "#\n",
      "#59-ul\n",
      "136.29\n",
      "#1-C1\n",
      "789.15\n",
      "#\n"
     ]
    }
   ],
   "source": [
    "list_test = []\n",
    "for i in range(28):\n",
    "    name = i+1\n",
    "    test = 'preprocess_test\\\\'+ str(name) + '.jpg'\n",
    "    list_test.append(pytesseract.image_to_string(Image.open(test)))\n",
    "for i in list_test:\n",
    "    print('#{}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Using real-time data augmentation.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`steps_per_epoch=None` is only valid for a generator based on the `keras.utils.Sequence` class. Please specify `steps_per_epoch` or use the `keras.utils.Sequence` class.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8a3414cf39f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    117\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m                         workers=4)\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;31m# Save model and weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m             raise ValueError('`steps_per_epoch=None` is only valid for a'\n\u001b[0m\u001b[0;32m     56\u001b[0m                              \u001b[1;34m' generator based on the '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m                              \u001b[1;34m'`keras.utils.Sequence`'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: `steps_per_epoch=None` is only valid for a generator based on the `keras.utils.Sequence` class. Please specify `steps_per_epoch` or use the `keras.utils.Sequence` class."
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Train a simple deep CNN on the CIFAR10 small images dataset.\n",
    "\n",
    "It gets to 75% validation accuracy in 25 epochs, and 79% after 50 epochs.\n",
    "(it's still underfitting at that point, though).\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 26us/step - loss: 0.2397 - acc: 0.9263 - val_loss: 0.1041 - val_acc: 0.9683\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1021 - acc: 0.9695 - val_loss: 0.0875 - val_acc: 0.97221024 - acc: 0.\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0740 - acc: 0.9776 - val_loss: 0.0718 - val_acc: 0.9800\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0604 - acc: 0.9825 - val_loss: 0.0758 - val_acc: 0.9794\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0493 - acc: 0.9853 - val_loss: 0.0810 - val_acc: 0.9797\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0439 - acc: 0.9867 - val_loss: 0.0930 - val_acc: 0.9779\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0356 - acc: 0.9889 - val_loss: 0.0960 - val_acc: 0.9786\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0340 - acc: 0.9895 - val_loss: 0.0894 - val_acc: 0.9823\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0290 - acc: 0.9912 - val_loss: 0.0832 - val_acc: 0.9826\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0285 - acc: 0.9920 - val_loss: 0.0917 - val_acc: 0.9812\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.0278 - acc: 0.9919 - val_loss: 0.1090 - val_acc: 0.9812\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0259 - acc: 0.9931 - val_loss: 0.1096 - val_acc: 0.9800\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0240 - acc: 0.9934 - val_loss: 0.0902 - val_acc: 0.9840\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0234 - acc: 0.9938 - val_loss: 0.1028 - val_acc: 0.9823\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0217 - acc: 0.9942 - val_loss: 0.0874 - val_acc: 0.9858\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0193 - acc: 0.9947 - val_loss: 0.1006 - val_acc: 0.9831\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0200 - acc: 0.9948 - val_loss: 0.1016 - val_acc: 0.9840\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.0191 - acc: 0.9947 - val_loss: 0.1081 - val_acc: 0.9835\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.0191 - acc: 0.9951 - val_loss: 0.1141 - val_acc: 0.9835\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0188 - acc: 0.995 - 1s 19us/step - loss: 0.0191 - acc: 0.9952 - val_loss: 0.1104 - val_acc: 0.9831\n",
      "Test loss: 0.11043125896120068\n",
      "Test accuracy: 0.9831\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "img = Image.open('five.jpg')\n",
    "# print(np.array(img).shape)\n",
    "image = img.resize((28,28), Image.LANCZOS)\n",
    "image = np.array(image)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "img = np.reshape(image, (1,28*28))\n",
    "a = model.predict(img)\n",
    "ind = a.tolist()[0]\n",
    "print(ind.index(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
