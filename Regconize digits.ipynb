{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "import keras\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OCR_scan(img_path = '', pre = 'thresh', save_path = '', number_pics = ''):\n",
    "    image = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    if pre == 'thresh':\n",
    "        ret, gray = cv2.threshold(gray, 0, 255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "    elif pre =='blur':\n",
    "        gray = cv2.medianBlur(gray, 3)\n",
    "    save_into = save_path+number_pics+'.jpg'\n",
    "    cv2.imwrite(save_into, gray) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = 'crop_image\\\\'\n",
    "pre1 = 'thresh'\n",
    "pre2 = 'blur'\n",
    "save_path1 = 'preprocess_thresh\\\\'\n",
    "save_path2 = 'preprocess_blur\\\\'\n",
    "count = '1'\n",
    "count_str = 1\n",
    "for i in os.listdir(img_list):\n",
    "    img_path = img_list+i\n",
    "    OCR_scan(img_path = img_path, pre = pre1, save_path = save_path1, number_pics = count)\n",
    "    OCR_scan(img_path = img_path, pre = pre2, save_path = save_path2, number_pics = count)\n",
    "    count_str += 1\n",
    "    count = str(count_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'preprocess_thresh\\\\'\n",
    "list_thresh = []\n",
    "list_blur = []\n",
    "list_o = []\n",
    "list_test = []\n",
    "for i in range(28):\n",
    "    name = i+1\n",
    "    thresh = filename + str(name) + '.jpg'\n",
    "    blur = 'preprocess_blur\\\\'+ str(name) + '.jpg'\n",
    "    original = 'crop_image\\\\'+ str(name) + '.jpg'\n",
    "    test = 'preprocess_test\\\\'+ str(name) + '.jpg'\n",
    "    list_thresh.append(pytesseract.image_to_string(Image.open(thresh)))\n",
    "    list_blur.append(pytesseract.image_to_string(Image.open(blur)))\n",
    "    list_o.append(pytesseract.image_to_string(Image.open(original)))\n",
    "    list_test.append(pytesseract.image_to_string(Image.open(test)))\n",
    "\n",
    "# print(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#J 59 PA j\n",
      "664.80\n",
      "#62 HS\n",
      "7108\n",
      "#\n",
      "#\n",
      "#1\n",
      "99.97\n",
      "#\n",
      "#ead\n",
      "043.09\n",
      "#\n",
      "#BY 59-41\n",
      "so7 00\n",
      "#59-81\n",
      "385.59\n",
      "#54-H}\n",
      "6982\n",
      "#\n",
      "#59°51\n",
      "09841\n",
      "#81-61\n",
      "135.56\n",
      "#60-F1\n",
      "506.70\n",
      "#Be \"1\n",
      "0200\n",
      "#16M\n",
      "06.\n",
      "#\n",
      "#S5-Po i\n",
      "2840\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#136.29\n",
      "#\n",
      "#59-(2\n",
      "316.61\n"
     ]
    }
   ],
   "source": [
    "for i in list_thresh:\n",
    "    print('#{}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#59897\n",
      "#B 99°C2\n",
      "012.08\n",
      "#ie\n",
      "043.09\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#39-51\n",
      "098.41\n",
      "#81-61\n",
      "135.56\n",
      "#60:F1\n",
      "506.70\n",
      "#\n",
      "#1\n",
      "0\n",
      "\n",
      "6-H\n",
      "61\n",
      "\n",
      "i\n",
      "#\n",
      "#Gar) ¢\n",
      "7840)\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#136.29\n",
      "#70-01\n",
      "/39 16\n",
      "#39-(2\n",
      "316.01\n"
     ]
    }
   ],
   "source": [
    "for i in list_blur:\n",
    "    print('#{}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#, 59-P1 '\n",
      "664.80\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#136.29\n",
      "#\n",
      "#59-(7\n",
      "316.01\n",
      "#\n",
      "#\n",
      "#\n",
      "#U1]\n",
      "98.97\n",
      "#\n",
      "#78-G)\n",
      "043.08)\n",
      "#59-E]\n",
      "708.50\n",
      "#\n",
      "#\n",
      "#36-HT\n",
      "4882\n",
      "#am 59-51\n",
      "098.41)\n",
      "#81-61\n",
      "1135.56\n",
      "#60-F1\n",
      "506.70\n",
      "#63-/\n",
      "0200\n",
      "#\n",
      "#\n",
      "#55-79\n",
      "7840)\n",
      "#\n",
      "#\n"
     ]
    }
   ],
   "source": [
    "for i in list_o:\n",
    "    print('#{}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unrecognized image mode",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-a657ba8f0905>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# ret, gray = cv2.threshold(closing, 180, 255,cv2.THRESH_BINARY)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'uint8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpytesseract\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[1;34m(obj, mode)\u001b[0m\n\u001b[0;32m   2534\u001b[0m             \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2536\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfrombuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"raw\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mfrombuffer\u001b[1;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[0;32m   2477\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2478\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2479\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfrombytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mfrombytes\u001b[1;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[0;32m   2409\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2410\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2411\u001b[1;33m     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2412\u001b[0m     \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrombytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2413\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mnew\u001b[1;34m(mode, size, color)\u001b[0m\n\u001b[0;32m   2373\u001b[0m         \u001b[0mcolor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageColor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcolor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2375\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: unrecognized image mode"
     ]
    }
   ],
   "source": [
    "img_path = 'crop_image\\\\1.jpg'\n",
    "image = cv2.imread(img_path,0)\n",
    "# plt.imshow(image, cmap = 'gray')\n",
    "# hist,bins = np.histogram(image.flatten(),256,[0,255]) \n",
    "# plt.imshow(hist,cmap = 'gray')\n",
    "img = cv2.equalizeHist(image)\n",
    "ret, img = cv2.threshold(img, 180, 255,cv2.THRESH_BINARY)\n",
    "\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "closing = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "opening = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "# ret, gray = cv2.threshold(closing, 180, 255,cv2.THRESH_BINARY)\n",
    "test = Image.fromarray(closing.astype('uint8'), 'gray')\n",
    "text = pytesseract.image_to_string(Image.open(closing))\n",
    "print(text)\n",
    "plt.imshow(closing, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = 'crop_image\\\\'\n",
    "# img = cv2.imread(img_path,0)\n",
    "# ret, gray = cv2.threshold(img, 150, 255,cv2.THRESH_BINARY)\n",
    "# plt.imshow(gray, cmap = 'gray')\n",
    "def OCR_test(img_path = '', pre = 'thresh', save_path = '', number_pics = ''):\n",
    "    image = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    if pre == 'thresh':\n",
    "        ret, gray = cv2.threshold(gray, 180, 255,cv2.THRESH_BINARY)\n",
    "#     elif pre =='blur':\n",
    "#         gray = cv2.medianBlur(gray, 3)\n",
    "    save_into = save_path+number_pics+'.jpg'\n",
    "    cv2.imwrite(save_into, gray) \n",
    "count = '1'\n",
    "count_str = 1\n",
    "for i in os.listdir(img_list):\n",
    "    img_path = img_list+i\n",
    "    OCR_test(img_path = img_path, pre = 'thresh', save_path = 'preprocess_test\\\\', number_pics = count)\n",
    "    count_str += 1\n",
    "    count = str(count_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#59-P1\n",
      "661.80\n",
      "#\n",
      "#FT,\n",
      "170.78\n",
      "#\n",
      "#59-1\n",
      "98.97]\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#59-B1 |\n",
      "38559\n",
      "#50H\n",
      "6882 fi\n",
      "#\n",
      "#9-51 |\n",
      "098.41]\n",
      "#\n",
      "#§0-F\n",
      "506.70)\n",
      "#63-41]\n",
      "02004\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#\n",
      "#ae “TT\n",
      "#\n",
      "#\n",
      "#\n",
      "#59-ul\n",
      "136.29\n",
      "#1-C1\n",
      "789.15\n",
      "#\n"
     ]
    }
   ],
   "source": [
    "list_test = []\n",
    "for i in range(28):\n",
    "    name = i+1\n",
    "    test = 'preprocess_test\\\\'+ str(name) + '.jpg'\n",
    "    list_test.append(pytesseract.image_to_string(Image.open(test)))\n",
    "for i in list_test:\n",
    "    print('#{}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Using real-time data augmentation.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`steps_per_epoch=None` is only valid for a generator based on the `keras.utils.Sequence` class. Please specify `steps_per_epoch` or use the `keras.utils.Sequence` class.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8a3414cf39f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    117\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m                         workers=4)\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;31m# Save model and weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m             raise ValueError('`steps_per_epoch=None` is only valid for a'\n\u001b[0m\u001b[0;32m     56\u001b[0m                              \u001b[1;34m' generator based on the '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m                              \u001b[1;34m'`keras.utils.Sequence`'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: `steps_per_epoch=None` is only valid for a generator based on the `keras.utils.Sequence` class. Please specify `steps_per_epoch` or use the `keras.utils.Sequence` class."
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Train a simple deep CNN on the CIFAR10 small images dataset.\n",
    "\n",
    "It gets to 75% validation accuracy in 25 epochs, and 79% after 50 epochs.\n",
    "(it's still underfitting at that point, though).\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "img = Image.open('five.jpg')\n",
    "# print(np.array(img).shape)\n",
    "image = img.resize((28,28), Image.LANCZOS)\n",
    "image = np.array(image)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[[1,2,3],[1,2,3]],[[1,2,3],[1,2,3]]])\n",
    "b = np.array([[[1,2,3],[1,2,3]],[[1,2,3],[1,2,3]],[[1,2,3],[1,2,3]]])\n",
    "\n",
    "print(np.concatenate((a,b),axis=0).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "'''\n",
    "For save data\n",
    "'''\n",
    "def save_obj(obj,name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 9.293680297397769 %\n",
      "Done 18.587360594795538 %\n",
      "Done 27.881040892193308 %\n",
      "Done 37.174721189591075 %\n",
      "Done 46.468401486988846 %\n",
      "Done 55.762081784386616 %\n",
      "Done 65.05576208178438 %\n",
      "Done 74.34944237918215 %\n",
      "Done 83.64312267657992 %\n",
      "Done 92.93680297397769 %\n",
      "Done 100 %\n"
     ]
    }
   ],
   "source": [
    "# Take hog vetor and set label for all data positive\n",
    "positive_path = '.\\\\charTrainset\\\\'\n",
    "\n",
    "X_train_positive = np.zeros((1076,672))\n",
    "count = 0\n",
    "for digits in os.listdir(positive_path):\n",
    "    for pics in os.listdir(positive_path+digits):\n",
    "        image = cv2.imread(positive_path+digits+'\\\\'+pics)\n",
    "        X_train_positive[count], hog_image = hog(img,orientations=8, pixels_per_cell=(2, 2), cells_per_block=(1, 1), \n",
    "                                        visualise = True,multichannel=True,feature_vector = True) \n",
    "        count+=1\n",
    "        if count%100==0:\n",
    "            print('Done {} %'.format((count*100)/1076))\n",
    "print('Done 100 %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\skimage\\feature\\_hog.py:239: skimage_deprecation: Argument `visualise` is deprecated and will be changed to `visualize` in v0.16\n",
      "  'be changed to `visualize` in v0.16', skimage_deprecation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 9.293680297397769 %\n",
      "Done 18.587360594795538 %\n",
      "Done 27.881040892193308 %\n",
      "Done 37.174721189591075 %\n",
      "Done 46.468401486988846 %\n",
      "Done 55.762081784386616 %\n",
      "Done 65.05576208178438 %\n",
      "Done 74.34944237918215 %\n",
      "Done 83.64312267657992 %\n",
      "Done 92.93680297397769 %\n",
      "Done 100 %\n"
     ]
    }
   ],
   "source": [
    "# Take hog vetor and set label for all data positive\n",
    "positive_path = '.\\\\charTrainset\\\\'\n",
    "X_train_positive = np.zeros((1076,672))\n",
    "label_positive = np.zeros((1076,))\n",
    "count = 0\n",
    "for digits in os.listdir(positive_path):\n",
    "    for pics in os.listdir(positive_path+digits):\n",
    "        image = cv2.imread(positive_path+digits+'\\\\'+pics)\n",
    "        X_train_positive[count], hog_image = hog(image,orientations=8, pixels_per_cell=(2, 2), cells_per_block=(1, 1), \n",
    "                                        visualise = True,multichannel=True,feature_vector = True)\n",
    "        label_positive[count]=1\n",
    "        count+=1\n",
    "        if count%100==0:\n",
    "            print('Done {} %'.format((count*100)/1076))\n",
    "print('Done 100 %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 1.075268817204301 %\n",
      "Done 2.150537634408602 %\n",
      "Done 3.225806451612903 %\n",
      "Done 4.301075268817204 %\n",
      "Done 5.376344086021505 %\n",
      "Done 6.451612903225806 %\n",
      "Done 7.526881720430108 %\n",
      "Done 8.602150537634408 %\n",
      "Done 9.67741935483871 %\n",
      "Done 10.75268817204301 %\n",
      "Done 11.827956989247312 %\n",
      "Done 12.903225806451612 %\n",
      "Done 13.978494623655914 %\n",
      "Done 15.053763440860216 %\n",
      "Done 16.129032258064516 %\n",
      "Done 17.204301075268816 %\n",
      "Done 18.27956989247312 %\n",
      "Done 19.35483870967742 %\n",
      "Done 20.43010752688172 %\n",
      "Done 21.50537634408602 %\n",
      "Done 22.580645161290324 %\n",
      "Done 23.655913978494624 %\n",
      "Done 24.731182795698924 %\n",
      "Done 25.806451612903224 %\n",
      "Done 26.881720430107528 %\n",
      "Done 27.956989247311828 %\n",
      "Done 29.032258064516128 %\n",
      "Done 30.107526881720432 %\n",
      "Done 31.182795698924732 %\n",
      "Done 32.25806451612903 %\n",
      "Done 33.333333333333336 %\n",
      "Done 34.40860215053763 %\n",
      "Done 35.483870967741936 %\n",
      "Done 36.55913978494624 %\n",
      "Done 37.634408602150536 %\n",
      "Done 38.70967741935484 %\n",
      "Done 39.784946236559136 %\n",
      "Done 40.86021505376344 %\n",
      "Done 41.935483870967744 %\n",
      "Done 43.01075268817204 %\n",
      "Done 44.086021505376344 %\n",
      "Done 45.16129032258065 %\n",
      "Done 46.236559139784944 %\n",
      "Done 47.31182795698925 %\n",
      "Done 48.38709677419355 %\n",
      "Done 49.46236559139785 %\n",
      "Done 50.53763440860215 %\n",
      "Done 51.61290322580645 %\n",
      "Done 52.68817204301075 %\n",
      "Done 53.763440860215056 %\n",
      "Done 54.83870967741935 %\n",
      "Done 55.913978494623656 %\n",
      "Done 56.98924731182796 %\n",
      "Done 58.064516129032256 %\n",
      "Done 59.13978494623656 %\n",
      "Done 60.215053763440864 %\n",
      "Done 61.29032258064516 %\n",
      "Done 62.365591397849464 %\n",
      "Done 63.44086021505376 %\n",
      "Done 64.51612903225806 %\n",
      "Done 65.59139784946237 %\n",
      "Done 66.66666666666667 %\n",
      "Done 67.74193548387096 %\n",
      "Done 68.81720430107526 %\n",
      "Done 69.89247311827957 %\n",
      "Done 70.96774193548387 %\n",
      "Done 72.04301075268818 %\n",
      "Done 73.11827956989248 %\n",
      "Done 74.19354838709677 %\n",
      "Done 75.26881720430107 %\n",
      "Done 76.34408602150538 %\n",
      "Done 77.41935483870968 %\n",
      "Done 78.49462365591398 %\n",
      "Done 79.56989247311827 %\n",
      "Done 80.64516129032258 %\n",
      "Done 81.72043010752688 %\n",
      "Done 82.79569892473118 %\n",
      "Done 83.87096774193549 %\n",
      "Done 84.94623655913979 %\n",
      "Done 86.02150537634408 %\n",
      "Done 87.09677419354838 %\n",
      "Done 88.17204301075269 %\n",
      "Done 89.24731182795699 %\n",
      "Done 90.3225806451613 %\n",
      "Done 91.39784946236558 %\n",
      "Done 92.47311827956989 %\n",
      "Done 93.54838709677419 %\n",
      "Done 94.6236559139785 %\n",
      "Done 95.6989247311828 %\n",
      "Done 96.7741935483871 %\n",
      "Done 97.84946236559139 %\n",
      "Done 98.9247311827957 %\n",
      "Done 100.0 %\n",
      "Done 100 %\n"
     ]
    }
   ],
   "source": [
    "# Take hog vetor and set label for all data negative\n",
    "negative_path1 = ['.\\\\training-samples\\\\detection\\\\negatives\\\\','.\\\\training-samples\\\\icdar\\\\negatives\\\\']\n",
    "X_train_negative = np.zeros((9300,672))\n",
    "label_negative = np.zeros((9300,))\n",
    "count = 0\n",
    "for path in negative_path1:\n",
    "    for pics in os.listdir(path):\n",
    "        img = Image.open(path+pics)\n",
    "        image = img.resize((12,28))\n",
    "        image_np = np.array(image)\n",
    "        X_train_negative[count], hog_image = hog(image_np,orientations=8, pixels_per_cell=(2, 2), cells_per_block=(1, 1), \n",
    "                                        visualise = True,multichannel=True,feature_vector = True)\n",
    "        label_negative[count]=0\n",
    "        count+=1\n",
    "        if count%100==0:\n",
    "            print('Done {} %'.format((count*100)/9300))\n",
    "print('Done 100 %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine together and then save to pickle file\n",
    "X_train = np.concatenate((X_train_positive,X_train_negative), axis = 0)\n",
    "y_train = np.concatenate((label_positive,label_negative))\n",
    "save_obj(X_train,'training_data')\n",
    "save_obj(y_train,'training_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\skimage\\feature\\_hog.py:239: skimage_deprecation: Argument `visualise` is deprecated and will be changed to `visualize` in v0.16\n",
      "  'be changed to `visualize` in v0.16', skimage_deprecation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 90.09009009009009 %\n",
      "Done 100 %\n"
     ]
    }
   ],
   "source": [
    "# Take hog vetor and set label for all test data negative\n",
    "test_path = '.\\\\test_data\\\\negative\\\\'\n",
    "X_test_negative = np.zeros((111,672))\n",
    "label_test_negative = np.zeros((111,))\n",
    "count = 0\n",
    "for pics in os.listdir(test_path):\n",
    "    img = Image.open(test_path+pics)\n",
    "    image = img.resize((12,28))\n",
    "    image_np = np.array(image)\n",
    "    X_test_negative[count], hog_image = hog(image_np,orientations=8, pixels_per_cell=(2, 2), cells_per_block=(1, 1), \n",
    "                                    visualise = True,multichannel=True,feature_vector = True)\n",
    "    label_test_negative[count]=0\n",
    "    count+=1\n",
    "    if count%100==0:\n",
    "        print('Done {} %'.format((count*100)/111))\n",
    "print('Done 100 %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take hog vetor and set label for all test data positive\n",
    "test_path = '.\\\\test_data\\\\positive\\\\train_32x32.mat'\n",
    "dict_mat = scipy.io.loadmat(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\skimage\\feature\\_hog.py:239: skimage_deprecation: Argument `visualise` is deprecated and will be changed to `visualize` in v0.16\n",
      "  'be changed to `visualize` in v0.16', skimage_deprecation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "all_pics = dict_mat['X']\n",
    "shape = all_pics.shape[3]\n",
    "X_test_positive = np.zeros((100,672))\n",
    "label_test_positive = np.zeros((100,))\n",
    "for count in range(100):\n",
    "    img = all_pics[:,:,:,count]\n",
    "    img = Image.fromarray(img)\n",
    "    image = img.resize((12,28))\n",
    "    image_np = np.array(image)\n",
    "    X_test_positive[count], hog_image = hog(image_np,orientations=8, pixels_per_cell=(2, 2), cells_per_block=(1, 1), \n",
    "                                    visualise = True,multichannel=True,feature_vector = True)\n",
    "    label_test_positive[count]=1\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine together and then save to pickle file\n",
    "X_test = np.concatenate((X_test_positive,X_test_negative), axis = 0)\n",
    "y_test = np.concatenate((label_test_positive,label_test_negative))\n",
    "save_obj(X_train,'test_data')\n",
    "save_obj(y_train,'test_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10376, 672)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
