{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\admins\\anaconda3\\envs\\ebox\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\admins\\anaconda3\\envs\\ebox\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\admins\\anaconda3\\envs\\ebox\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\admins\\anaconda3\\envs\\ebox\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\admins\\anaconda3\\envs\\ebox\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\admins\\anaconda3\\envs\\ebox\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\admins\\anaconda3\\envs\\ebox\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\admins\\anaconda3\\envs\\ebox\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\admins\\anaconda3\\envs\\ebox\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\admins\\anaconda3\\envs\\ebox\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\admins\\anaconda3\\envs\\ebox\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\admins\\anaconda3\\envs\\ebox\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import colorsys\n",
    "import os\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "\n",
    "from yolo3.model import yolo_eval, yolo_body, tiny_yolo_body\n",
    "from yolo3.utils import letterbox_image\n",
    "import os\n",
    "from keras.utils import multi_gpu_model\n",
    "import time \n",
    "\n",
    "def non_max_suppression(boxes, max_bbox_overlap, scores=None):\n",
    "   \n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    boxes = boxes.astype(np.float)\n",
    "    pick = []\n",
    "\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "    \n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    if scores is not None:\n",
    "        idxs = np.argsort(scores)\n",
    "    else:\n",
    "        idxs = np.argsort(y2)\n",
    "\n",
    "        \n",
    "    while len(idxs) > 0:\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "        \n",
    "        iou = w*h\n",
    "        out = np.where(iou/area[i] > 0.8)\n",
    "\n",
    "        \n",
    "        idxs = np.delete(\n",
    "            idxs, np.concatenate(\n",
    "                ([last], np.where(overlap > max_bbox_overlap)[0],out[0])))\n",
    "\n",
    "    return pick\n",
    "\n",
    "\n",
    "class YOLO(object):\n",
    "    _defaults = {\n",
    "        \"anchors_path\": 'model_data/yolo_anchors.txt',\n",
    "        \"score\" : 0.3,\n",
    "        \"iou\" : 0.5,\n",
    "        \"model_image_size\" : (416, 416),\n",
    "        \"gpu_num\" : 1,\n",
    "    }\n",
    "\n",
    "    @classmethod\n",
    "    def get_defaults(cls, n):\n",
    "        if n in cls._defaults:\n",
    "            return cls._defaults[n]\n",
    "        else:\n",
    "            return \"Unrecognized attribute name '\" + n + \"'\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        # model with dataset 600 and no Text button, no Back\n",
    "#         model = 'C:/Users/ADMINS/Desktop/all_model/model/model_supervised_RL/version1_lr_1e-7_loss_14.h5' \n",
    "#         model = 'C:/Users/ADMINS/Desktop/version3_tiny.h5'\n",
    "    \n",
    "        model = 'C:/Users/ADMINS/Desktop/test.h5'\n",
    "#         model = 'C:\\\\Users\\\\ADMINS\\\\Desktop\\\\all_model\\\\tiny_model\\\\trained_weights_v3.h5'\n",
    "#         classes = 'C:\\\\Users\\\\ADMINS\\\\Desktop\\\\all_model\\\\tiny_model\\\\classes.txt'\n",
    "        classes= 'C:/Users/ADMINS/Desktop/classes.txt'\n",
    "        self.model_path = model\n",
    "        self.classes_path = classes\n",
    "           \n",
    "           \n",
    "        self.__dict__.update(self._defaults) # set up default values\n",
    "        self.__dict__.update(kwargs) # and update with user overrides\n",
    "        self.class_names = self._get_class()\n",
    "        self.anchors = self._get_anchors()\n",
    "        self.sess = K.get_session()\n",
    "        self.boxes, self.scores, self.classes = self.generate()\n",
    "\n",
    "    def _get_class(self):\n",
    "        classes_path = os.path.expanduser(self.classes_path)\n",
    "        with open(classes_path) as f:\n",
    "            class_names = f.readlines()\n",
    "        class_names = [c.strip() for c in class_names]\n",
    "        return class_names\n",
    "\n",
    "    def _get_anchors(self):\n",
    "        anchors_path = os.path.expanduser(self.anchors_path)\n",
    "        with open(anchors_path) as f:\n",
    "            anchors = f.readline()\n",
    "        anchors = [float(x) for x in anchors.split(',')]\n",
    "        return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "    def generate(self):\n",
    "        model_path = os.path.expanduser(self.model_path)\n",
    "        assert model_path.endswith('.h5'), 'Keras model or weights must be a .h5 file.'\n",
    "\n",
    "        # Load model, or construct model and load weights.\n",
    "        num_anchors = len(self.anchors)\n",
    "        num_classes = len(self.class_names)\n",
    "        is_tiny_version = num_anchors==6 # default setting\n",
    "                \n",
    "        try:\n",
    "            self.yolo_model = load_model(model_path, compile=False)\n",
    "        except:\n",
    "            self.yolo_model = tiny_yolo_body(Input(shape=(None,None,3)), num_anchors//2, num_classes) \\\n",
    "                if is_tiny_version else yolo_body(Input(shape=(None,None,3)), num_anchors//3, num_classes)\n",
    "            self.yolo_model.load_weights(self.model_path) # make sure model, anchors and classes match\n",
    "        else:\n",
    "            assert self.yolo_model.layers[-1].output_shape[-1] == \\\n",
    "                num_anchors/len(self.yolo_model.output) * (num_classes + 5), \\\n",
    "                'Mismatch between model and given anchor and class sizes'\n",
    "\n",
    "        # Generate colors for drawing bounding boxes.\n",
    "        hsv_tuples = [(x / len(self.class_names), 1., 1.)\n",
    "                      for x in range(len(self.class_names))]\n",
    "        self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "        self.colors = list(\n",
    "            map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n",
    "                self.colors))\n",
    "        np.random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "        np.random.shuffle(self.colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "        np.random.seed(None)  # Reset seed to default.\n",
    "        \n",
    "\n",
    "        # Generate output tensor targets for filtered bounding boxes.\n",
    "        self.input_image_shape = K.placeholder(shape=(2, ))\n",
    "        if self.gpu_num>=2:\n",
    "            self.yolo_model = multi_gpu_model(self.yolo_model, gpus=self.gpu_num)\n",
    "        boxes, scores, classes = yolo_eval(self.yolo_model.output, self.anchors,\n",
    "                len(self.class_names), self.input_image_shape,\n",
    "                score_threshold=self.score, iou_threshold=self.iou)\n",
    "        return boxes, scores, classes\n",
    "\n",
    "    def detect_image(self, image, show = False):\n",
    "\n",
    "        if self.model_image_size != (None, None):\n",
    "            assert self.model_image_size[0]%32 == 0, 'Multiples of 32 required'\n",
    "            assert self.model_image_size[1]%32 == 0, 'Multiples of 32 required'\n",
    "            boxed_image = letterbox_image(image, tuple(reversed(self.model_image_size)))\n",
    "        else:\n",
    "            new_image_size = (image.width - (image.width % 32),\n",
    "                              image.height - (image.height % 32))\n",
    "            boxed_image = letterbox_image(image, new_image_size)\n",
    "        image_data = np.array(boxed_image, dtype='float32')\n",
    "\n",
    "        image_data /= 255.\n",
    "        image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "\n",
    "        out_boxes, out_scores, out_classes = self.sess.run(\n",
    "            [self.boxes, self.scores, self.classes],\n",
    "            feed_dict={\n",
    "                self.yolo_model.input: image_data,\n",
    "                self.input_image_shape: [image.size[1], image.size[0]],\n",
    "                K.learning_phase(): 0\n",
    "            })\n",
    "        idx = non_max_suppression(out_boxes, 0.55, out_scores)\n",
    "        out_boxes, out_scores, out_classes = out_boxes[idx], out_scores[idx], out_classes[idx]\n",
    "        \n",
    "        if show:\n",
    "            font = ImageFont.truetype(font='font/FiraMono-Medium.otf',\n",
    "                        size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n",
    "            thickness = (image.size[0] + image.size[1]) // 300\n",
    "            \n",
    "            for i, c in reversed(list(enumerate(out_classes))):\n",
    "                predicted_class = self.class_names[c]\n",
    "                box = out_boxes[i]\n",
    "                score = out_scores[i]\n",
    "\n",
    "                label = '{} {:.2f}'.format(predicted_class, score)\n",
    "                draw = ImageDraw.Draw(image)\n",
    "                label_size = draw.textsize(label, font)\n",
    "\n",
    "                top, left, bottom, right = box\n",
    "                top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "                left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "                bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "                right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "                # print(label, (left, top), (right, bottom))\n",
    "\n",
    "                if top - label_size[1] >= 0:\n",
    "                    text_origin = np.array([left-150, top - label_size[1]])\n",
    "                else:\n",
    "                    text_origin = np.array([left-150, top + 1])\n",
    "\n",
    "                # My kingdom for a good redistributable image drawing library.\n",
    "                for i in range(thickness):\n",
    "                    draw.rectangle(\n",
    "                        [left + i, top + i, right - i, bottom - i],\n",
    "                        outline=self.colors[c])\n",
    "                draw.rectangle(\n",
    "                    [tuple(text_origin), tuple(text_origin + label_size)],\n",
    "                    fill=self.colors[c])\n",
    "                draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "                del draw\n",
    "\n",
    "        return image, out_boxes, out_scores, out_classes\n",
    "\n",
    "    def close_session(self):\n",
    "        self.sess.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\admins\\anaconda3\\envs\\ebox\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "yolo = YOLO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "path = 'C:/Users/ADMINS/Desktop/newest/'\n",
    "for file in os.listdir(path):\n",
    "#     print(file)\n",
    "    img = Image.open(path+file)\n",
    "    image,_,_,_ =  yolo.detect_image(img,show=True)\n",
    "    image = np.array(image)\n",
    "    image = image[:,:,::-1]\n",
    "    cv2.imwrite('C:/Users/ADMINS/Desktop/small_data_result/'+file,image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "import pytesseract as pt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def blackAndWhite(img):\n",
    "    # take input is binary image, find the box contain text\n",
    "    position = []\n",
    "    temp = []\n",
    "    found = 0\n",
    "    for k,v in enumerate(img[:,0]):\n",
    "        if k < 10 and v!=0:\n",
    "            continue\n",
    "        if found == 2:\n",
    "            position.append(temp)\n",
    "            temp = []\n",
    "            found = 0\n",
    "        try:\n",
    "            gradient = np.abs(img[k,0]-img[k+1,0])\n",
    "            if gradient > 0:\n",
    "                temp.append(k)\n",
    "                found+=1\n",
    "        except:\n",
    "            pass\n",
    "    return position\n",
    "\n",
    "def readTextBox(img, boxes, classes, labels):\n",
    "    # class of text box is 6\n",
    "    boxes = boxes[np.where(classes == 6)]\n",
    "    \n",
    "    # check if the box is empty or not\n",
    "    try:\n",
    "        if not boxes:\n",
    "            return img\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    boxes = np.round(boxes).astype(np.int64)\n",
    "    \n",
    "    # convert image to correct channels\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # convert image to gray\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # find box contain all text\n",
    "    x_min = np.min(boxes[:,1])\n",
    "    x_max = np.max(boxes[:,3])\n",
    "    y_top = np.min(boxes[:,0])\n",
    "    y_bot = np.max(boxes[:,2])\n",
    "    \n",
    "    # extract it from original image\n",
    "    image = gray[y_top:y_bot,x_min:x_max]\n",
    "    \n",
    "    H,W = image.shape\n",
    "#     return image\n",
    "    # take threshold, set thresh very small because the word is always black\n",
    "    ret,thresh = cv2.threshold(image,20,255,cv2.THRESH_BINARY_INV)\n",
    "    # Openning horizontal to remove the small object\n",
    "    # E.g: the tail of word 'g' \n",
    "    kernel = np.ones((3,1),np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    # Dilate horizontal to get the white box contain text\n",
    "    kernel = np.ones((1,5000),np.uint8)\n",
    "    dilation = cv2.dilate(opening,kernel,iterations = 1)\n",
    "    \n",
    "    # this part only use for show result\n",
    "    color = [255,0,0]\n",
    "    thickness = 3\n",
    "    # plus 10 pixels to top and bottom to make sure it contain enough information \n",
    "    for p in blackAndWhite(dilation):\n",
    "        i = image[(p[0]-10):(p[1]+10),:]\n",
    "#         return i\n",
    "        txt = pt.image_to_string(i)\n",
    "        if txt == '':\n",
    "            try:\n",
    "                ret,thresh1 = cv2.threshold(i,50,255,cv2.THRESH_BINARY_INV)\n",
    "                txt = pt.image_to_string(thresh1)\n",
    "            except:\n",
    "                pass\n",
    "        max = -1\n",
    "        for k,v in labels.items():\n",
    "            if similar(v,txt) > max:\n",
    "                max = similar(v,txt)\n",
    "                idx = k\n",
    "        \n",
    "        cv2.rectangle(img,(x_min,p[0]+y_top-10),(x_max,p[1]+y_top+10), color, thickness)\n",
    "        if max < 0.7:\n",
    "            continue\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "        cv2.putText(img, labels[idx], (x_min-500,p[0]+y_top), font, 1, [0,255,0], 2,cv2.LINE_AA)\n",
    "    img = img[:,:,::-1]\n",
    "    return img\n",
    "\n",
    "    \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admins\\anaconda3\\envs\\ebox\\lib\\site-packages\\ipykernel_launcher.py:22: RuntimeWarning: overflow encountered in ubyte_scalars\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import json \n",
    "\n",
    "with open('labels.json', 'r') as l:\n",
    "    labels = json.loads(l.read())\n",
    "# pic = Image.open('C:/Users/ADMINS/Desktop/image/(83).png')\n",
    "pic = Image.open('C:/Users/ADMINS/Desktop/hari/image/1.png')\n",
    "# pic = Image.open('C:/Users/ADMINS/Desktop/test.png')\n",
    "image, boxes, scores, classes = yolo.detect_image(image = pic, show =False)\n",
    "# print(pic.shape)\n",
    "image = np.array(image)\n",
    "# print(image.shape)\n",
    "img = readTextBox(image, boxes, classes, labels)\n",
    "cv2.imwrite('C:/Users/ADMINS/Desktop/fix.png', img)\n",
    "cv2.namedWindow('image', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('image', 1000,600)\n",
    "\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admins\\anaconda3\\envs\\ebox\\lib\\site-packages\\ipykernel_launcher.py:22: RuntimeWarning: overflow encountered in ubyte_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.png\n",
      "11.png\n",
      "2.png\n",
      "3.png\n",
      "4.png\n",
      "5.png\n",
      "6.png\n",
      "7.png\n",
      "8.png\n",
      "9.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "t = []\n",
    "path = 'C:/Users/ADMINS/Desktop/image/'\n",
    "path = 'C:/Users/ADMINS/Desktop/hari/image/'\n",
    "# dictionary contain all label\n",
    "with open('labels.json', 'r') as l:\n",
    "    labels = json.loads(l.read())\n",
    "    \n",
    "for img in os.listdir(path):\n",
    "    print(img)\n",
    "    t1 = time.time()\n",
    "    pic = Image.open(path+img)\n",
    "    _, boxes, _, classes = yolo.detect_image(image = pic)\n",
    "    cv2.imwrite('C:/Users/ADMINS/Desktop/fix/'+img, \\\n",
    "                readTextBox(np.array(pic), boxes, classes, labels))\n",
    "    t.append(time.time()-t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1751042222976684\n"
     ]
    }
   ],
   "source": [
    "a = np.array(t)\n",
    "print(np.average(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract as pt\n",
    "import cv2\n",
    "\n",
    "# path = 'C:/Users/TobyCurtis/Desktop/(4).png'\n",
    "\n",
    "# image = cv2.imread(path,0)\n",
    "# image = image[y_top:y_bot,x_min:x_max]\n",
    "# text = pt.image_to_string(image)\n",
    "# print(text)\n",
    "\n",
    "image = img\n",
    "boxes = np.round(boxes).astype(np.int64)\n",
    "\n",
    "ret,thresh = cv2.threshold(image,170,255,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "kernel = np.ones((3,1),np.uint8)\n",
    "opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "# kernel = np.ones((1,3),np.uint8)\n",
    "# opening = cv2.morphologyEx(opening, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "kernel = np.ones((1,5000),np.uint8)\n",
    "# closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel)\n",
    "dilation = cv2.dilate(opening,kernel,iterations = 1)\n",
    "\n",
    "cv2.imshow('w3', image)\n",
    "# cv2.imshow('w2', opening)\n",
    "cv2.imshow('w1',thresh)\n",
    "# cv2.imshow('w',dilation)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7894736842105263"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = 'Language Option English' \n",
    "t2 = 'Language Option'\n",
    "similar(t1,t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.206016926765442\n"
     ]
    }
   ],
   "source": [
    "a = np.array(t)\n",
    "print(np.average(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "\n",
    "goto = 'C:/Users/ADMINS/Desktop/Ebox/Source2/result/'\n",
    "source = 'C:/Users/ADMINS/Desktop/Ebox/Source2/image/'\n",
    "special_source = 'C:/Users/ADMINS/Desktop/Ebox/Source1/special_test/'\n",
    "result = 'C:/Users/ADMINS/Desktop/Ebox/Source1/special_result/'\n",
    "\n",
    "new_source = 'C:/Users/ADMINS/Desktop/Data_Test_image/'\n",
    "new_result = 'C:/Users/ADMINS/Desktop/result1/'\n",
    "\n",
    "\n",
    "# time_ex = []\n",
    "iou_1 = []\n",
    "iou_2 = []\n",
    "iou_3 = []\n",
    "iou_4 = []\n",
    "iou_5 = []\n",
    "for file in os.listdir(new_source):\n",
    "    pic = Image.open(new_source+file)\n",
    "    image, boxex, scores, classes = yolo.detect_image(image = pic)\n",
    "\n",
    "    img = np.array(image)\n",
    "    img = img[:,:,::-1]\n",
    "    cv2.imwrite(new_result+file,img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('C:/Users/ADMINS/Desktop/Ebox/Source1/test.txt','r')\n",
    "d = {}\n",
    "for line in f:\n",
    "    a = line\n",
    "    temp_dict = {}\n",
    "    b = a.split(' ')\n",
    "    name = b[0].split('/')[-1]\n",
    "    count = 1\n",
    "    while(count<len(b)-1):\n",
    "        value = [int(i) for i in b[count].split(',')]\n",
    "        temp_dict[value[-1]]=value[:-1]\n",
    "        count+=1\n",
    "    d[name]=temp_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [1198, 48, 1270, 119], 1: [1201, 152, 1267, 213], 2: [1204, 254, 1270, 317], 3: [1200, 354, 1270, 424], 4: [1202, 456, 1269, 520], 5: [1201, 561, 1268, 620]}\n"
     ]
    }
   ],
   "source": [
    "temp_dict = {}\n",
    "b = a.split(' ')\n",
    "name = b[0].split('/')\n",
    "count = 1\n",
    "while(count<len(b)-1):\n",
    "    value = [int(i) for i in b[count].split(',')]\n",
    "    temp_dict[value[-1]]=value[:-1]\n",
    "    count+=1\n",
    "print(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8076923076923077"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def iou(box_gt, box_pre):\n",
    "    x_left = max(box_pre[1],box_gt[0])\n",
    "    x_right = min(box_pre[3], box_gt[2])\n",
    "    y_top = max(box_pre[0], box_gt[1])\n",
    "    y_bot = min(box_pre[2], box_gt[3])\n",
    "    if x_left > x_right:\n",
    "        return 0\n",
    "    intersect_area = (x_right-x_left)*(y_bot-y_top)\n",
    "    \n",
    "    gt_area = (box_gt[2]-box_gt[0])*(box_gt[3]-box_gt[1])\n",
    "    pre_area = (box_pre[3]-box_pre[1])*(box_pre[2]-box_pre[0])\n",
    "    \n",
    "    result = intersect_area/(gt_area+pre_area-intersect_area)\n",
    "    return result\n",
    "box_pre = [  50, 1193,    113, 1273 ]\n",
    "box_gt = [1198,48,1270,119]\n",
    "iou(box_gt,box_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\admins\\anaconda3\\envs\\ebox\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\admins\\anaconda3\\envs\\ebox\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\admins\\anaconda3\\envs\\ebox\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\admins\\anaconda3\\envs\\ebox\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\admins\\anaconda3\\envs\\ebox\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\admins\\anaconda3\\envs\\ebox\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\admins\\anaconda3\\envs\\ebox\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\admins\\anaconda3\\envs\\ebox\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\admins\\anaconda3\\envs\\ebox\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\admins\\anaconda3\\envs\\ebox\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\admins\\anaconda3\\envs\\ebox\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\admins\\anaconda3\\envs\\ebox\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import colorsys\n",
    "import os\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "\n",
    "from yolo3.model import yolo_eval, yolo_body, tiny_yolo_body\n",
    "from yolo3.utils import letterbox_image\n",
    "import os\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "def non_max_suppression(boxes, max_bbox_overlap, scores=None):\n",
    "   \n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    boxes = boxes.astype(np.float)\n",
    "    pick = []\n",
    "\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "    \n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    if scores is not None:\n",
    "        idxs = np.argsort(scores)\n",
    "    else:\n",
    "        idxs = np.argsort(y2)\n",
    "\n",
    "        \n",
    "    while len(idxs) > 0:\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "        \n",
    "        iou = w*h\n",
    "        out = np.where(iou/area[i] > 0.8)\n",
    "\n",
    "        \n",
    "        idxs = np.delete(\n",
    "            idxs, np.concatenate(\n",
    "                ([last], np.where(overlap > max_bbox_overlap)[0],out[0])))\n",
    "\n",
    "    return pick\n",
    "\n",
    "\n",
    "class YOLO(object):\n",
    "    _defaults = {\n",
    "        \"anchors_path\": 'model_data/yolo_anchors.txt',\n",
    "        \"score\" : 0.5,\n",
    "        \"iou\" : 0.5,\n",
    "        \"model_image_size\" : (416, 416),\n",
    "        \"gpu_num\" : 1,\n",
    "    }\n",
    "\n",
    "    @classmethod\n",
    "    def get_defaults(cls, n):\n",
    "        if n in cls._defaults:\n",
    "            return cls._defaults[n]\n",
    "        else:\n",
    "            return \"Unrecognized attribute name '\" + n + \"'\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        # model with dataset 600 and no Text button, no Back\n",
    "        model1 = 'C:/Users/ADMINS/Desktop/model/first_model/trained_weights_final.h5'\n",
    "        \n",
    "        # model with dataset 100 with 8 labels\n",
    "        # normal train, early stop\n",
    "        model2 = 'C:/Users/ADMINS/Desktop/model/OMEN_Text_Button/trained_weights_final.h5'\n",
    "        \n",
    "        # no early, no decay\n",
    "        model3 = 'C:/Users/ADMINS/Desktop/model/OMEN_model_non_early_non_decay/trained_weights_final.h5'\n",
    "        \n",
    "        class_6 = 'C:/Users/ADMINS/Desktop/Ebox/Source1/classes.txt'\n",
    "        class_8 = 'C:/Users/ADMINS/Desktop/classes.txt'\n",
    "        self.model_path = model3\n",
    "        self.classes_path = class_8\n",
    "           \n",
    "           \n",
    "        self.__dict__.update(self._defaults) # set up default values\n",
    "        self.__dict__.update(kwargs) # and update with user overrides\n",
    "        self.class_names = self._get_class()\n",
    "        self.anchors = self._get_anchors()\n",
    "        self.sess = K.get_session()\n",
    "        self.boxes, self.scores, self.classes = self.generate()\n",
    "\n",
    "    def _get_class(self):\n",
    "        classes_path = os.path.expanduser(self.classes_path)\n",
    "        with open(classes_path) as f:\n",
    "            class_names = f.readlines()\n",
    "        class_names = [c.strip() for c in class_names]\n",
    "        return class_names\n",
    "\n",
    "    def _get_anchors(self):\n",
    "        anchors_path = os.path.expanduser(self.anchors_path)\n",
    "        with open(anchors_path) as f:\n",
    "            anchors = f.readline()\n",
    "        anchors = [float(x) for x in anchors.split(',')]\n",
    "        return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "    def generate(self):\n",
    "        model_path = os.path.expanduser(self.model_path)\n",
    "        assert model_path.endswith('.h5'), 'Keras model or weights must be a .h5 file.'\n",
    "\n",
    "        # Load model, or construct model and load weights.\n",
    "        num_anchors = len(self.anchors)\n",
    "        num_classes = len(self.class_names)\n",
    "        is_tiny_version = num_anchors==6 # default setting\n",
    "        try:\n",
    "            self.yolo_model = load_model(model_path, compile=False)\n",
    "        except:\n",
    "            self.yolo_model = tiny_yolo_body(Input(shape=(None,None,3)), num_anchors//2, num_classes) \\\n",
    "                if is_tiny_version else yolo_body(Input(shape=(None,None,3)), num_anchors//3, num_classes)\n",
    "            self.yolo_model.load_weights(self.model_path) # make sure model, anchors and classes match\n",
    "        else:\n",
    "            assert self.yolo_model.layers[-1].output_shape[-1] == \\\n",
    "                num_anchors/len(self.yolo_model.output) * (num_classes + 5), \\\n",
    "                'Mismatch between model and given anchor and class sizes'\n",
    "\n",
    "        print('{} model, anchors, and classes loaded.'.format(model_path))\n",
    "        \n",
    "        # Generate colors for drawing bounding boxes.\n",
    "        hsv_tuples = [(x / len(self.class_names), 1., 1.)\n",
    "                      for x in range(len(self.class_names))]\n",
    "        self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "        self.colors = list(\n",
    "            map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n",
    "                self.colors))\n",
    "        np.random.seed(10101)  # Fixed seed for consistent colors across runs.\n",
    "        np.random.shuffle(self.colors)  # Shuffle colors to decorrelate adjacent classes.\n",
    "        np.random.seed(None)  # Reset seed to default.\n",
    "        \n",
    "\n",
    "        # Generate output tensor targets for filtered bounding boxes.\n",
    "        self.input_image_shape = K.placeholder(shape=(2, ))\n",
    "        if self.gpu_num>=2:\n",
    "            self.yolo_model = multi_gpu_model(self.yolo_model, gpus=self.gpu_num)\n",
    "        boxes, scores, classes = yolo_eval(self.yolo_model.output, self.anchors,\n",
    "                len(self.class_names), self.input_image_shape,\n",
    "                score_threshold=self.score, iou_threshold=self.iou)\n",
    "        return boxes, scores, classes\n",
    "\n",
    "    def detect_image(self, image, show = False):\n",
    "\n",
    "        if self.model_image_size != (None, None):\n",
    "            assert self.model_image_size[0]%32 == 0, 'Multiples of 32 required'\n",
    "            assert self.model_image_size[1]%32 == 0, 'Multiples of 32 required'\n",
    "            boxed_image = letterbox_image(image, tuple(reversed(self.model_image_size)))\n",
    "        else:\n",
    "            new_image_size = (image.width - (image.width % 32),\n",
    "                              image.height - (image.height % 32))\n",
    "            boxed_image = letterbox_image(image, new_image_size)\n",
    "        image_data = np.array(boxed_image, dtype='float32')\n",
    "\n",
    "        image_data /= 255.\n",
    "        image_data = np.expand_dims(image_data, 0)  # Add batch dimension.\n",
    "\n",
    "        out_boxes, out_scores, out_classes = self.sess.run(\n",
    "            [self.boxes, self.scores, self.classes],\n",
    "            feed_dict={\n",
    "                self.yolo_model.input: image_data,\n",
    "                self.input_image_shape: [image.size[1], image.size[0]],\n",
    "                K.learning_phase(): 0\n",
    "            })\n",
    "        idx = non_max_suppression(out_boxes, 0.55, out_scores)\n",
    "        out_boxes, out_scores, out_classes = out_boxes[idx], out_scores[idx], out_classes[idx]\n",
    "        \n",
    "        if show:\n",
    "            font = ImageFont.truetype(font='font/FiraMono-Medium.otf',\n",
    "                        size=np.floor(3e-2 * image.size[1] + 0.5).astype('int32'))\n",
    "            thickness = (image.size[0] + image.size[1]) // 300\n",
    "            \n",
    "            for i, c in reversed(list(enumerate(out_classes))):\n",
    "                predicted_class = self.class_names[c]\n",
    "                box = out_boxes[i]\n",
    "                score = out_scores[i]\n",
    "\n",
    "                label = '{} {:.2f}'.format(predicted_class, score)\n",
    "                draw = ImageDraw.Draw(image)\n",
    "                label_size = draw.textsize(label, font)\n",
    "\n",
    "                top, left, bottom, right = box\n",
    "                top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "                left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "                bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "                right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "                # print(label, (left, top), (right, bottom))\n",
    "\n",
    "                if top - label_size[1] >= 0:\n",
    "                    text_origin = np.array([left-150, top - label_size[1]])\n",
    "                else:\n",
    "                    text_origin = np.array([left-150, top + 1])\n",
    "\n",
    "                # My kingdom for a good redistributable image drawing library.\n",
    "                for i in range(thickness):\n",
    "                    draw.rectangle(\n",
    "                        [left + i, top + i, right - i, bottom - i],\n",
    "                        outline=self.colors[c])\n",
    "                draw.rectangle(\n",
    "                    [tuple(text_origin), tuple(text_origin + label_size)],\n",
    "                    fill=self.colors[c])\n",
    "                draw.text(text_origin, label, fill=(0, 0, 0), font=font)\n",
    "                del draw\n",
    "\n",
    "        return image, out_boxes, out_scores, out_classes\n",
    "\n",
    "    def close_session(self):\n",
    "        self.sess.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/ADMINS/Desktop/model/OMEN_model_non_early_non_decay/trained_weights_final.h5 model, anchors, and classes loaded.\n",
      "WARNING:tensorflow:From c:\\users\\admins\\anaconda3\\envs\\ebox\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "yolo = YOLO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/ADMINS/Desktop/model/OMEN_model_non_early_non_decay/trained_weights_final.h5 model, anchors, and classes loaded.\n"
     ]
    }
   ],
   "source": [
    "a = yolo.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(<tf.Tensor 'conv2d_209/BiasAdd:0' shape=(?, ?, ?, 39) dtype=float32>,\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(yolo.yolo_model.output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-17-40f70cd6e643>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-17-40f70cd6e643>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    print(list(f.keys())\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "f = h5py.File('C:/Users/ADMINS/Desktop/model/OMEN_model_non_early_non_decay/trained_weights_final.h5', 'r')\n",
    "print(list(f.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
